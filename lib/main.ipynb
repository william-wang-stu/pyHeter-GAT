{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始数据格式分析\n",
    "#   Initial Feature List (Randomly Initialized)\n",
    "#       TODO: user profile可以作为User的Initial Feature的若干维度, i.e. Location\n",
    "#   Heterogeneous Adjacency Matrix <- Load Data\n",
    "#   Anchor Link Matrix <- Load Data\n",
    "\n",
    "# Twitter <-> FourSquare\n",
    "#   Anchor Link Matrix: fsquare-users.pkl.gz id<->twitter\n",
    "#   NOTE: df[\"twitter\"].dropna(), 有些FourSquare User不存在Twitter Id\n",
    "\n",
    "# Foursquare Social Network\n",
    "#   User: fsquare-users.pkl.gz id\n",
    "#   Tweet: fsquare-tips.pkl.gz text <- 构造text_id\n",
    "#   Loc: fsquare-locations.pkl.gz id <- 抽象为简单的数字loc_id\n",
    "#   User-User: fsquare-follows.pkl.gz user1->user2\n",
    "#   User-Tweet: fsquare-tips.pkl.gz user_id -> text <- text_id\n",
    "#   User-Loc: fsquare-tips.pkl.gz user_id -> loc_id <- (int)loc_id\n",
    "\n",
    "# Twitter Social Network\n",
    "# NOTE: Loc类型的节点是没有的, 只有部分User(~514610/8178957)存在User-Loc(Lat,Lng)的关系\n",
    "# 意思是只有少部分用户去了某些地方可能会附上定位坐标\n",
    "# NOTE: 从数据分析来看(见该数据文件夹中的data-format.ipynb), \n",
    "# Location指的就是(Lat,Lng)组合, User-Location指的是user-(Lat,Lng)\n",
    "#   User: twitter-users.pkl.gz username\n",
    "#   Tweet: twitter-tweets.pkl.gz text <- 构造text_id\n",
    "#   Loc: twitter-tweets.pkl.gz (lat,lng) <- 去NaN, 去重\n",
    "#   User-User: twitter-follows.pkl.gz user1 -> user2\n",
    "#   User-Tweet: twitter-tweets.pkl.gz username -> text <- text_id\n",
    "#   User-Loc: twitter-tweets.pkl.gz username -> (lat,lng) <- 去NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 19:06:53,861 Note: NumExpr detected 56 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-07-22 19:06:53,863 NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from log import logger\n",
    "from utils import network_types, node_types, edge_types, get_node_types, extend_edges, create_sparse, get_sparse_tensor, get_anchor_link_matrix, get_train_test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "\n",
    "# Init Var: edges\n",
    "for network_type in network_types:\n",
    "    nodes[network_type] = {}\n",
    "    for node_type in node_types:\n",
    "        nodes[network_type][node_type] = {}\n",
    "        with open(f\"../output/graph/nodemap-{network_type}-{node_type}.txt\", \"r\") as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                if network_type == \"Twitter\" and node_type == \"Tweet\" and idx > 50000:\n",
    "                    break\n",
    "                if network_type == \"Twitter\" and node_type == \"Location\" and idx > 100000:\n",
    "                    break\n",
    "                parts = line[:-1].split(' ')\n",
    "                # NOTE: strange!!! Tweet Nodes Nums are different between r and w\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                key, value = parts\n",
    "                if key.isdigit():\n",
    "                    key = int(key)\n",
    "                nodes[network_type][node_type][key] = int(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = {}\n",
    "\n",
    "# Init Var: edges\n",
    "for network_type in network_types:\n",
    "    edges[network_type] = {}\n",
    "    for edge_type in edge_types:\n",
    "        edges[network_type][edge_type] = []\n",
    "        with open(f\"../output/graph/edgelist-{network_type}-{edge_type}.txt\", \"r\") as f:\n",
    "            for line in f:\n",
    "                from_, to_ = line[:-1].split(' ')\n",
    "                if network_type == \"Twitter\" and edge_type == \"U-T\" and (int(from_) > 50000 or int(to_) > 50000):\n",
    "                    continue\n",
    "                if network_type == \"Twitter\" and edge_type == \"U-L\" and (int(from_) > 100000 or int(to_) > 100000):\n",
    "                    continue\n",
    "                edges[network_type][edge_type].append((from_, to_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Nodes: total=155195, num_users=5223, num_tweets=49971, num_locs=100001\n",
      "Twitter Edges: total=1353786, num_U-U=164919, num_U-T=899773, num_U-L=289094\n",
      "Foursquare Nodes: total=146195, num_users=5392, num_tweets=46616, num_locs=94187\n",
      "Foursquare Edges: total=174142, num_U-U=76972, num_U-T=48585, num_U-L=48585\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Twitter Nodes: num_users=5223, num_tweets=6960800, num_locs=256497\n",
    "Twitter Edges: num_U-U=164919, num_U-T=8178952, num_U-L=514610\n",
    "Foursquare Nodes: num_users=5392, num_tweets=46617, num_locs=94187\n",
    "Foursquare Edges: num_U-U=76972, num_U-T=48585, num_U-L=48585\n",
    "\n",
    "Twitter Nodes: num_users=5223, num_tweets=6960800, num_locs=256497\n",
    "Twitter Nodes: num_users=5223, num_tweets=6960377, num_locs=256497\n",
    "Twitter Edges: num_U-U=164919, num_U-T=8178952, num_U-L=514610\n",
    "Foursquare Nodes: num_users=5392, num_tweets=46617, num_locs=94187\n",
    "Foursquare Nodes: num_users=5392, num_tweets=46616, num_locs=94187\n",
    "Foursquare Edges: num_U-U=76972, num_U-T=48585, num_U-L=48585\n",
    "\"\"\"\n",
    "for network_type in network_types:\n",
    "    num_users  = len(nodes[network_type][\"User\"])\n",
    "    num_tweets = len(nodes[network_type][\"Tweet\"])\n",
    "    num_locs   = len(nodes[network_type][\"Location\"])\n",
    "    print(f\"{network_type} Nodes: total={num_users+num_tweets+num_locs}, num_users={num_users}, num_tweets={num_tweets}, num_locs={num_locs}\")\n",
    "\n",
    "    # num_users  = len(new_nodes[network_type][\"User\"])\n",
    "    # num_tweets = len(new_nodes[network_type][\"Tweet\"])\n",
    "    # num_locs   = len(new_nodes[network_type][\"Location\"])\n",
    "    # print(f\"{network_type} Nodes: num_users={num_users}, num_tweets={num_tweets}, num_locs={num_locs}\")\n",
    "\n",
    "    num_uu = len(edges[network_type][\"U-U\"])\n",
    "    num_ut = len(edges[network_type][\"U-T\"])\n",
    "    num_ul = len(edges[network_type][\"U-L\"])\n",
    "    print(f\"{network_type} Edges: total={num_uu+num_ut+num_ul}, num_U-U={num_uu}, num_U-T={num_ut}, num_U-L={num_ul}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1_t=User, node2_t=Tweet, start_idx_node1_t=0, start_idx_node2_t=5223\n",
      "node1_t=User, node2_t=Location, start_idx_node1_t=0, start_idx_node2_t=55194\n",
      "node1_t=User, node2_t=Tweet, start_idx_node1_t=0, start_idx_node2_t=5392\n",
      "node1_t=User, node2_t=Location, start_idx_node1_t=0, start_idx_node2_t=52008\n"
     ]
    }
   ],
   "source": [
    "# NOTE: 所需构造的异构图是(|Rs|, N, N), N=N_user+N_tweet+N_location\n",
    "# -> 送入第一层次的GAT时, 不同异构图的邻接矩阵不同, 得到的N*D'的emb也不同, 且每次只从中选取(N_user,D')的emb以备后用\n",
    "# -> 送入第二层次的GAT时, 我们默认N=N_user\n",
    "\n",
    "matrices = {}\n",
    "\n",
    "for network_type in network_types:\n",
    "    matrices[network_type] = {}\n",
    "\n",
    "    start_idx_mp = {}\n",
    "    indices = 0\n",
    "    for node_type in node_types:\n",
    "        start_idx_mp[node_type] = indices\n",
    "        indices += len(nodes[network_type][node_type])\n",
    "    # print(start_idx_mp)\n",
    "\n",
    "    for edge_type in edge_types:\n",
    "        node1_t, node2_t = get_node_types(edge_type)\n",
    "        extended_edges = edges[network_type][edge_type]\n",
    "        if start_idx_mp[node1_t] or start_idx_mp[node2_t]:\n",
    "            print(f\"node1_t={node1_t}, node2_t={node2_t}, start_idx_node1_t={start_idx_mp[node1_t]}, start_idx_node2_t={start_idx_mp[node2_t]}\")\n",
    "            extended_edges = extend_edges(extended_edges, start_idx_mp[node1_t], start_idx_mp[node2_t])\n",
    "        matrices[network_type][edge_type] = create_sparse(extended_edges, indices, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Features\n",
    "#   Use Word2Vec to initialize those Tweet Nodes\n",
    "#   Else use Random Assignment to initialize other Nodes, User Nodes and Location Nodes\n",
    "import torch\n",
    "\n",
    "initial_features = {}\n",
    "\n",
    "for network_type in network_types:\n",
    "    indices = 0\n",
    "    for node_type in node_types:\n",
    "        indices += len(nodes[network_type][node_type])\n",
    "    initial_features[network_type] = torch.rand(indices, 100)\n",
    "\n",
    "hadj = {}\n",
    "for network_type in network_types:\n",
    "    hadj[network_type] = []\n",
    "    for edge_type in edge_types:\n",
    "        adj = get_sparse_tensor(matrices[network_type][edge_type])\n",
    "        hadj[network_type].append(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "import torch.optim as optim\n",
    "from itertools import chain\n",
    "from model import HeterogeneousGraphAttention\n",
    "from loss import TypeAwareAlignmentLoss\n",
    "\n",
    "# 1. Prepare Data\n",
    "alm = get_anchor_link_matrix(nodes)\n",
    "train_row, train_col, test_row, test_col = get_train_test_pairs(nodes)\n",
    "\n",
    "# 2. Model, Optimizer, Loss\n",
    "model_twitter = HeterogeneousGraphAttention(n_user=len(nodes[\"Twitter\"][\"User\"]), n_units=[100, 128], gpu_device_ids=[6,7,8])\n",
    "model_fsquare = HeterogeneousGraphAttention(n_user=len(nodes[\"Foursquare\"][\"User\"]), n_units=[100, 128])\n",
    "# if torch.cuda.is_available():\n",
    "#     model_twitter.cuda()\n",
    "#     model_fsquare.cuda()\n",
    "\n",
    "optimizer = optim.Adam(chain(model_twitter.parameters(), model_fsquare.parameters()), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "loss_fn = TypeAwareAlignmentLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "model_twitter.train()\n",
    "model_fsquare.train()\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "x1 = initial_features[\"Twitter\"].to('cuda:1')\n",
    "hadj1 = [elem.to('cuda:1') for elem in hadj[\"Twitter\"]]\n",
    "# model_twitter = model_twitter.to('cuda:1')\n",
    "output_tw = model_twitter(x1, hadj1)\n",
    "\n",
    "x2 = initial_features[\"Foursquare\"].to('cuda:6')\n",
    "hadj2 = [elem.to('cuda:6') for elem in hadj[\"Foursquare\"]]\n",
    "model_fsquare = model_fsquare.to('cuda:6')\n",
    "output_fs = model_fsquare(x2, hadj2)\n",
    "\n",
    "# loss_train = loss_fn(alm, output_tw, output_fs)\n",
    "\n",
    "# loss_train.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "# logger.info(f\"Train in Epoch={0}: Loss={loss_train:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tw = output_tw.to('cuda:9')\n",
    "output_fs = output_fs.to('cuda:9')\n",
    "\n",
    "loss_train = loss_fn(alm, output_tw[:500], output_fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 19:09:50,903 Device idx=0 Allocated: 0.7221593856811523\n",
      "2022-07-22 19:09:50,908 Device idx=0 Cached: 0.787109375\n",
      "2022-07-22 19:09:50,909 Device idx=1 Allocated: 0.1059103012084961\n",
      "2022-07-22 19:09:50,911 Device idx=1 Cached: 0.197265625\n",
      "2022-07-22 19:09:50,913 Device idx=2 Allocated: 0.0\n",
      "2022-07-22 19:09:50,915 Device idx=2 Cached: 0.0\n",
      "2022-07-22 19:09:50,916 Device idx=3 Allocated: 0.0\n",
      "2022-07-22 19:09:50,917 Device idx=3 Cached: 0.001953125\n",
      "2022-07-22 19:09:50,919 Device idx=4 Allocated: 0.0\n",
      "2022-07-22 19:09:50,921 Device idx=4 Cached: 0.001953125\n",
      "2022-07-22 19:09:50,922 Device idx=5 Allocated: 0.0\n",
      "2022-07-22 19:09:50,924 Device idx=5 Cached: 0.001953125\n",
      "2022-07-22 19:09:50,925 Device idx=6 Allocated: 4.2127203941345215\n",
      "2022-07-22 19:09:50,927 Device idx=6 Cached: 5.560546875\n",
      "2022-07-22 19:09:50,928 Device idx=7 Allocated: 4.662710189819336\n",
      "2022-07-22 19:09:50,930 Device idx=7 Cached: 7.896484375\n",
      "2022-07-22 19:09:50,931 Device idx=8 Allocated: 1.996872901916504\n",
      "2022-07-22 19:09:50,933 Device idx=8 Cached: 3.505859375\n",
      "2022-07-22 19:09:50,934 Device idx=9 Allocated: 0.020247459411621094\n",
      "2022-07-22 19:09:50,936 Device idx=9 Cached: 5.6484375\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    logger.info(f\"Device idx={i} Allocated: {torch.cuda.memory_allocated(i)/1024**3}\")\n",
    "    logger.info(f\"Device idx={i} Cached: {torch.cuda.memory_reserved(i)/1024**3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training\n",
    "\n",
    "# model_twitter.train()\n",
    "# model_fsquare.train()\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# output_tw = model_twitter(initial_features[\"Twitter\"], hadj[\"Twitter\"])\n",
    "# output_fs = model_fsquare(initial_features[\"Foursquare\"], hadj[\"Foursquare\"])\n",
    "\n",
    "# loss_train = loss_fn(alm, output_tw, output_fs)\n",
    "\n",
    "# loss_train.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "# logger.info(f\"Train in Epoch={0}: Loss={loss_train:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluating\n",
    "\n",
    "# k = 30\n",
    "# ratio = 0.8\n",
    "\n",
    "# model_twitter.eval()\n",
    "# model_fsquare.eval()\n",
    "\n",
    "# output_tw = model_twitter(initial_features[\"Twitter\"], hadj[\"Twitter\"])\n",
    "# output_fs = model_fsquare(initial_features[\"Foursquare\"], hadj[\"Foursquare\"])\n",
    "# print(\"Allocated: \", torch.cuda.memory_allocated(0)/1024**3)\n",
    "\n",
    "# loss_val = loss_fn(alm, output_tw, output_fs)\n",
    "\n",
    "# print(\"Allocated: \", torch.cuda.memory_allocated(0)/1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec Initial Features\n",
    "\n",
    "import word2vec\n",
    "\n",
    "model = word2vec.load('../data/raw2.bin', encoding=\"ISO-8859-1\", new_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import df_twitter_tweets\n",
    "\n",
    "for _, row in df_twitter_tweets.iterrows():\n",
    "    indexes, metrics = model.similar(row[\"text\"])\n",
    "    emb = model.generate_response(indexes, metrics).tolist()\n",
    "    print(emb)\n",
    "    emb = emb[0]\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
