{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 15:12:28,610 Note: NumExpr detected 56 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-09-26 15:12:28,611 NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "from utils import load_pickle, save_pickle, summarize_distribution\n",
    "from lib.log import logger\n",
    "import igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_pickle(\"/root/Lab_Related/data/Heter-GAT/Classic/graph/graph-directed.p\")\n",
    "diffusion_dict = load_pickle(\"/root/Lab_Related/data/Heter-GAT/Classic/ActionLog.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-param\n",
    "ego_size = 49 # without center node, which means containing ego_size + 1 nodes per batch\n",
    "Ntimestages = 8\n",
    "Nslice = Ntimestages + 1\n",
    "sample_ratio = 1\n",
    "restart_prob = 0.2\n",
    "walk_length = 1000\n",
    "min_degree, max_degree, min_active_neighbor = 3, 7635, 3\n",
    "min_degree, max_degree, min_active_neighbor = 3, 450, 3\n",
    "min_influence, max_influence = 30, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 15:21:20,318 [282, 159, 176, 176, 259, 389, 543, 735]\n",
      "2022-09-26 15:21:20,320 aidx=   0, hashtag= 186, cascades length=  120774, subgraph samples length=     0      0      0      6     11     21     56    124\n"
     ]
    }
   ],
   "source": [
    "from utils import SubGraphSample\n",
    "from typing import List, Any\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "subgraph_samples = [SubGraphSample() for _ in range(Ntimestages)]\n",
    "\n",
    "def random_walk_with_restart(g: igraph.Graph, start: List[int], restart_prob: float):\n",
    "    current = random.choice(seq=start)\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        stop = yield current\n",
    "        neighbors = g.neighbors(current, mode=\"out\")\n",
    "        if random.random() < restart_prob or len(neighbors) == 0:\n",
    "            current = random.choice(seq=start)\n",
    "        else:\n",
    "            current = random.choice(seq=neighbors)\n",
    "\n",
    "def create_sample(center_user: int, label: int, hashtag: int, time_stage: int, users_affected_now: List[int], subgraph_sample: SubGraphSample):\n",
    "    neighbors = graph.neighbors(center_user, mode=\"out\")\n",
    "    active_neighbors = set(users_affected_now) & set(neighbors)\n",
    "    inactive_neighbors = set(neighbors) - active_neighbors\n",
    "    active_neighbors, inactive_neighbors = list(active_neighbors), list(inactive_neighbors)\n",
    "    if len(active_neighbors) < min_active_neighbor:\n",
    "        return\n",
    "    \n",
    "    subnetwork_size = ego_size + 1\n",
    "    subnetwork = []\n",
    "    if len(active_neighbors) < ego_size:\n",
    "        subnetwork = set(active_neighbors)\n",
    "        for v in itertools.islice(\n",
    "            random_walk_with_restart(g=graph, start=[center_user]+active_neighbors,restart_prob=restart_prob),\n",
    "            walk_length\n",
    "        ):\n",
    "            if v != center_user and v not in subnetwork:\n",
    "                subnetwork.add(v)\n",
    "                if len(subnetwork) == ego_size:\n",
    "                    break\n",
    "        subnetwork = list(subnetwork)\n",
    "        if len(subnetwork) < ego_size:\n",
    "            return\n",
    "    else:\n",
    "        samples = np.random.choice(active_neighbors, size=ego_size, replace=False)\n",
    "        subnetwork = samples.tolist()\n",
    "    subnetwork.append(center_user)\n",
    "\n",
    "    ranks = np.array(subnetwork).argsort().argsort()\n",
    "    subgraph = graph.subgraph(subnetwork, implementation=\"create_from_scratch\")\n",
    "    adjacency = np.array(subgraph.get_adjacency().data, dtype=int)\n",
    "    adjacency = adjacency[ranks][:,ranks]\n",
    "    subgraph_sample.adj_matrices.append(adjacency)\n",
    "\n",
    "    influence_feature = np.zeros((subnetwork_size,2))\n",
    "    for idx, v in enumerate(subnetwork[:-1]):\n",
    "        if v in users_affected_now:\n",
    "            influence_feature[idx, 0] = 1\n",
    "    influence_feature[subnetwork_size-1,1] = 1\n",
    "    subgraph_sample.influence_features.append(influence_feature)\n",
    "\n",
    "    subgraph_sample.vertex_ids.append(np.array(subnetwork, dtype=int))\n",
    "    subgraph_sample.labels.append(label)\n",
    "    subgraph_sample.tags.append(hashtag)\n",
    "    subgraph_sample.time_stages.append(time_stage)\n",
    "\n",
    "def dump_data(dump_dirpath: str, adj_matrices, influence_features, vertex_ids, labels, tags, time_stages):\n",
    "    adj_matrices = np.array(adj_matrices)\n",
    "    influence_features = np.array(influence_features)\n",
    "    vertex_ids = np.array(vertex_ids)\n",
    "    labels = np.array(labels)\n",
    "    tags = np.array(tags)\n",
    "    time_stages = np.array(time_stages)\n",
    "\n",
    "    os.makedirs(dump_dirpath, exist_ok=True)\n",
    "    with open(os.path.join(dump_dirpath, \"adjacency_matrix.npy\"), \"wb\") as f:\n",
    "        np.save(f, adj_matrices)\n",
    "    with open(os.path.join(dump_dirpath, \"influence_feature.npy\"), \"wb\") as f:\n",
    "        np.save(f, influence_features)\n",
    "    with open(os.path.join(dump_dirpath, \"vertex_id.npy\"), \"wb\") as f:\n",
    "        np.save(f, vertex_ids)\n",
    "    with open(os.path.join(dump_dirpath, \"label.npy\"), \"wb\") as f:\n",
    "        np.save(f, labels)\n",
    "    with open(os.path.join(dump_dirpath, \"tag.npy\"), \"wb\") as f:\n",
    "        np.save(f, tags)\n",
    "    with open(os.path.join(dump_dirpath, \"time_stage.npy\"), \"wb\") as f:\n",
    "        np.save(f, time_stages)\n",
    "\n",
    "    logger.info(\"Dump %d instances in total\" % (len(labels)))\n",
    "\n",
    "def find_rightest_bound(timestamp: float, min_timestamp: float, time_span: float):\n",
    "    idx = int((timestamp-min_timestamp)//time_span)\n",
    "    return Ntimestages-1 if idx>=Ntimestages-1 else idx\n",
    "\n",
    "def get_samples(hashtag: int, cascades: List[Any], degree: List[int]):\n",
    "    \"\"\"\n",
    "    Function: 分别找到每个(cascades, time-stage)下的正负样本, 其中正样本指的是已激活的用户, 负样本指的是这些正样本的子节点\n",
    "    \"\"\"\n",
    "    cascade_item_idx = 0\n",
    "    users_affected_now = set()\n",
    "    users_affected_all = set([item[0] for item in cascades])\n",
    "    time_span = (cascades[-1][1]-cascades[0][1])/Ntimestages\n",
    "\n",
    "    for user, timestamp in cascades[1:]:\n",
    "        while cascade_item_idx < len(cascades) and cascades[cascade_item_idx][1] < timestamp:\n",
    "            users_affected_now.add(cascades[cascade_item_idx][0])\n",
    "            cascade_item_idx += 1\n",
    "        if len(users_affected_now) == 0 or user in users_affected_now:\n",
    "            continue\n",
    "        tidx = find_rightest_bound(timestamp, min_timestamp=cascades[0][1], time_span=time_span)\n",
    "        \n",
    "        # Pos\n",
    "        if degree[user] >= min_degree and degree[user] <= max_degree:\n",
    "            create_sample(center_user=user, label=1, hashtag=hashtag, time_stage=tidx, users_affected_now=users_affected_now, subgraph_sample=subgraph_samples[tidx])\n",
    "        \n",
    "        # Neg\n",
    "        neg_samples = list(set(graph.neighbors(user, mode=\"out\")) - users_affected_all)\n",
    "        neg_samples = np.random.choice(neg_samples, size=min(len(neg_samples), sample_ratio), replace=False)\n",
    "        for neg_sample in neg_samples:\n",
    "            if degree[neg_sample] >= min_degree and degree[neg_sample] <= max_degree:\n",
    "                create_sample(center_user=neg_sample, label=0, hashtag=hashtag, time_stage=tidx, users_affected_now=users_affected_now, subgraph_sample=subgraph_samples[tidx])\n",
    "\n",
    "degree = graph.degree(mode=\"out\")\n",
    "for aidx, (hashtag, cascades) in enumerate(diffusion_dict.items()):\n",
    "    get_samples(hashtag=hashtag, cascades=cascades, degree=degree)\n",
    "\n",
    "    logger.info(f\"aidx={aidx:>4}, hashtag={hashtag:>4}, cascades length={len(cascades):>8}, subgraph samples length=\" + \\\n",
    "        \" \".join([f\"{len(sample):>6}\" for sample in subgraph_samples])\n",
    "    )\n",
    "    break\n",
    "\n",
    "# for idx in range(Ntimestages):\n",
    "#     dump_data(\n",
    "#         dump_dirpath=f\"stages1/{idx}\",\n",
    "#         adj_matrices=subgraph_samples[idx].adj_matrices,\n",
    "#         influence_features=subgraph_samples[idx].influence_features,\n",
    "#         vertex_ids=subgraph_samples[idx].vertex_ids,\n",
    "#         labels=subgraph_samples[idx].labels,\n",
    "#         tags=subgraph_samples[idx].tags,\n",
    "#         time_stages=subgraph_samples[idx].time_stages,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2],)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def func(a=[]):\n",
    "#     a.append(2)\n",
    "#     return a\n",
    "\n",
    "func()\n",
    "func.__defaults__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_heternetwork_nodetype(current:int, nb_users:int=20000)->str:\n",
    "#     return \"Tweet\" if current >= nb_users else \"User\"\n",
    "\n",
    "# def static_vars(**kwargs):\n",
    "#     def decorate(func):\n",
    "#         for k in kwargs:\n",
    "#             setattr(func, k, kwargs[k])\n",
    "#         return func\n",
    "#     return decorate\n",
    "\n",
    "# @static_vars(node_cnts={\"User\":0, \"Tweet\":0}, max_cnts = {\"User\": 50, \"Tweet\": 50*20})\n",
    "# def control_node_cnts(current:int)->bool:\n",
    "#     node_type = get_heternetwork_nodetype(current)\n",
    "#     valid = control_node_cnts.node_cnts[node_type]+1<=control_node_cnts.max_cnts[node_type]\n",
    "#     if valid:\n",
    "#         control_node_cnts.node_cnts[node_type] += 1\n",
    "#     # logger.info(\"node_cnts: {}\".format(\" \".join(f\"{key}={value}\" for key,value in control_node_cnts.node_cnts.items())))\n",
    "#     return valid\n",
    "\n",
    "# def heter_random_walk_with_restart(g, start:List[int], restart_prob:float, valid_fn:Callable[[int],bool]):\n",
    "#     current = random.choice(start)\n",
    "#     stop = False\n",
    "#     valid_fn.node_cnts={\"User\":0, \"Tweet\":0}\n",
    "\n",
    "#     while not stop:\n",
    "#         stop = yield current\n",
    "#         valid = False\n",
    "        \n",
    "#         while not valid:\n",
    "#             node_type = get_heternetwork_nodetype(current)\n",
    "#             # NOTE: We treat all edges as directed ones\n",
    "#             # Bcz we create U-T Edges in the direction of user->tweet\n",
    "#             neighbor_mode = \"in\" if node_type == \"Tweet\" else \"out\"\n",
    "#             if random.random() < restart_prob or g.degree(current, mode=neighbor_mode)==0:\n",
    "#                 current = random.choice(start)\n",
    "#                 valid = valid_fn(current)\n",
    "#             else:\n",
    "#                 current = random.choice(g.neighbors(current, mode=neighbor_mode))\n",
    "#                 valid = valid_fn(current)\n",
    "#             # logger.info(f\"current={current}, valid={valid}\")\n",
    "\n",
    "# for v in itertools.islice(heter_random_walk_with_restart(graph, [2603], 0.2, control_node_cnts), 10):\n",
    "#     print(v)\n",
    "# print(control_node_cnts.node_cnts)\n",
    "\n",
    "# def get_samples(cascades: List[tuple[int,int]]):\n",
    "#     \"\"\"\n",
    "#     Function: 分别找到每个(cascades, time-stage)下的正负样本, 其中正样本指的是已激活的用户, 负样本指的是这些正样本的子节点\n",
    "#     \"\"\"\n",
    "#     pos_samples, neg_samples = [set() for _ in range(Nslice)], [set() for _ in range(Nslice)]\n",
    "\n",
    "#     cascade_item_idx = 0\n",
    "#     min_timestamp, max_timestamp = cascades[0][1], cascades[-1][1]\n",
    "#     time_span = (max_timestamp - min_timestamp) / Nslice\n",
    "#     users_affected_now = [set() for _ in range(Nslice)]\n",
    "    \n",
    "#     for tidx in range(Nslice)\n",
    "#         lower_b, upper_b = min_timestamp+tidx*time_span, min_timestamp+(tidx+1)*time_span\n",
    "#         cur_pos, cur_neg = set(), set()\n",
    "#         while cascade_item_idx < len(cascades) and cascades[cascade_item_idx][1] <= upper_b:\n",
    "#             cur_pos.add(cascades[cascade_item_idx][0])\n",
    "#             cur_neg |= set(graph.neighbors(cascades[cascade_item_idx][0], mode=\"out\"))\n",
    "#             cascade_item_idx += 1\n",
    "#         users_affected_now[tidx] = cur_pos\n",
    "#         if tidx >= 1:\n",
    "#             users_affected_now[tidx] |= users_affected_now[tidx-1]\n",
    "\n",
    "#         pos_samples[tidx] |= cur_pos\n",
    "#         neg_samples[tidx] |= cur_neg\n",
    "#         # if tidx >= 1:\n",
    "#         #     neg_samples[tidx-1] -= cur_pos\n",
    "        \n",
    "#     return pos_samples, neg_samples, users_affected_now\n",
    "\n",
    "# pos_samples, neg_samples, users_affected_now = get_samples(cascades=diffusion_dict[186])\n",
    "# pos_samples, neg_samples, users_affected_now = get_samples(cascades=cascades)\n",
    "# for tidx in range(len(users_affected_now)):\n",
    "#     for pos_sample in pos_samples[tidx]:\n",
    "#         if degree[pos_sample] >= min_degree and degree[pos_sample] <= max_degree:\n",
    "#             create_sample(center_user=pos_sample, label=1, users_affected_now=users_affected_now[tidx], subgraph_sample=subgraph_samples[tidx])\n",
    "    \n",
    "#     neg_users = np.random.choice(list(neg_samples[tidx]), size=min(len(neg_samples[tidx]), sample_ratio*len(pos_samples[tidx])), replace=False)\n",
    "#     for neg_sample in neg_users:\n",
    "#         if degree[neg_sample] >= min_degree and degree[neg_sample] <= max_degree:\n",
    "#             create_sample(center_user=neg_sample, label=0, users_affected_now=users_affected_now[tidx], subgraph_sample=subgraph_samples[tidx])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
