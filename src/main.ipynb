{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 arts_&_culture 611206\n",
      "1 business_&_entrepreneurs 119595\n",
      "2 celebrity_&_pop_culture 121572\n",
      "3 diaries_&_daily_life 294226\n",
      "4 family 119574\n",
      "5 fashion_&_style 124447\n",
      "6 film_tv_&_video 139726\n",
      "7 fitness_&_health 119588\n",
      "8 food_&_dining 153700\n",
      "9 gaming 119582\n",
      "10 learning_&_educational 120235\n",
      "11 music 199903\n",
      "12 news_&_social_concern 32777790\n",
      "13 other_hobbies 186934\n",
      "14 relationships 119580\n",
      "15 science_&_technology 120635\n",
      "16 sports 129964\n",
      "17 travel_&_adventure 120775\n",
      "[('news_&_social_concern', 32777790), ('arts_&_culture', 611206), ('diaries_&_daily_life', 294226), ('music', 199903), ('other_hobbies', 186934), ('food_&_dining', 153700), ('film_tv_&_video', 139726), ('sports', 129964), ('fashion_&_style', 124447), ('celebrity_&_pop_culture', 121572), ('travel_&_adventure', 120775), ('science_&_technology', 120635), ('learning_&_educational', 120235), ('business_&_entrepreneurs', 119595), ('fitness_&_health', 119588), ('gaming', 119582), ('relationships', 119580), ('family', 119574)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/topic_graph/topic_diffusion_graph_full_windowsize200.data\", 'rb') as f:\n",
    "# with open(\"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/topic_graph/topic_diffusion_graph_windowsize200.data\", 'rb') as f:\n",
    "    topic_graph = pickle.load(f)\n",
    "\n",
    "topic2label = {\n",
    "    \"0\": \"arts_&_culture\",\n",
    "    \"1\": \"business_&_entrepreneurs\",\n",
    "    \"2\": \"celebrity_&_pop_culture\",\n",
    "    \"3\": \"diaries_&_daily_life\",\n",
    "    \"4\": \"family\",\n",
    "    \"5\": \"fashion_&_style\",\n",
    "    \"6\": \"film_tv_&_video\",\n",
    "    \"7\": \"fitness_&_health\",\n",
    "    \"8\": \"food_&_dining\",\n",
    "    \"9\": \"gaming\",\n",
    "    \"10\": \"learning_&_educational\",\n",
    "    \"11\": \"music\",\n",
    "    \"12\": \"news_&_social_concern\",\n",
    "    \"13\": \"other_hobbies\",\n",
    "    \"14\": \"relationships\",\n",
    "    \"15\": \"science_&_technology\",\n",
    "    \"16\": \"sports\",\n",
    "    \"17\": \"travel_&_adventure\",\n",
    "    \"18\": \"youth_&_student_life\"\n",
    "}\n",
    "\n",
    "topic2num = {}\n",
    "for k, v in topic_graph.items():\n",
    "    print(k, topic2label[str(k)], v['edge_index'].shape[1])\n",
    "    topic2num[topic2label[str(k)]] = v['edge_index'].shape[1]\n",
    "\n",
    "topic2num = sorted(topic2num.items(), key=lambda x: x[1], reverse=True)\n",
    "print(topic2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27735\n",
      "737162\n"
     ]
    }
   ],
   "source": [
    "# 统计tweet数量\n",
    "import pickle\n",
    "\n",
    "# Twitter: 568,256; Weibo: 737,162\n",
    "# filepath = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/cascades.data\"\n",
    "filepath = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/cascades.data\"\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    cd = pickle.load(f)\n",
    "\n",
    "print(len(cd))\n",
    "# for k,v in cd.items():\n",
    "#     print(v.keys())\n",
    "#     break\n",
    "print(sum([len(v[\"user\"]) for k,v in cd.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/pyHeter-GAT-_-uOEIOh/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/topic_graph/topic_diffusion_graph_full_windowsize100.data\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['edge_index', 'edge_weight']\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, v.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology | Health | Entertainment | Geography | Mass_media | Society | Economy | Sports | Business | Politics | Food_and_drink | Internet | Communication | Time | Law | Military | Religion | Education | Humanities | Nature'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Technology | Health | Entertainment | Geography | Mass_media | Society | Economy | Sports | Business | Politics | Food_and_drink | Internet | Communication | Time | Law | Military | Religion | Education | Humanities | Nature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/pyHeter-GAT-_-uOEIOh/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Health | Military | Academic_disciplines | Politics | Nature | Law | Society | Economy | Science | Internet | Entertainment | Mass_media | Information | Philosophy | Food_and_drink | Education | Government | Business | Time | Religion | Technology | History | Sports | Human_behavior | Culture'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/topic_llm2/topic_diffusion_graph_full_windowsize7.data\", 'rb') as f:\n",
    "    graph_dict = pickle.load(f)\n",
    "\n",
    "\" | \".join([k for k, _ in graph_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3147, 6.6385, 2.544, 17.4957, 3.0107, 25.8497, 3.1278]\n",
      "[2.9572000000000003, 5.6712, 2.2775, 14.9852, 2.6774, 22.2799, 2.7795]\n",
      "[2.9973, 5.6244000000000005, 2.3168, 14.9034, 2.7152, 22.1659, 2.8171]\n",
      "[2.8455999999999997, 5.6069, 2.1391, 15.3856, 2.5555000000000003, 23.0368, 2.6624]\n"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "\n",
    "s = \"\"\"\n",
    "2024-07-04 23:19:20,445    - (Testing)    scores: MRR:0.033147 hits@10:0.066385 map@10:0.025440 hits@50:0.174957 map@50:0.030107 hits@100:0.258497 map@100:0.031278, elapse: 2.997 min, gpu memory usage=4896.000 MiB\n",
    "2024-05-21 01:47:13,000    - (Testing)    scores: MRR:0.029572 hits@10:0.056712 map@10:0.022775 hits@50:0.149852 map@50:0.026774 hits@100:0.222799 map@100:0.027795, elapse: 3.541 min, gpu memory usage=22318.000 MiB\n",
    "2024-05-21 19:48:49,839    - (Testing)    scores: MRR:0.029973 hits@10:0.056244 map@10:0.023168 hits@50:0.149034 map@50:0.027152 hits@100:0.221659 map@100:0.028171, elapse: 3.963 min, gpu memory usage=23364.000 MiB\n",
    "2024-05-21 06:50:13,475    - (Testing)    scores: MRR:0.028456 hits@10:0.056069 map@10:0.021391 hits@50:0.153856 map@50:0.025555 hits@100:0.230368 map@100:0.026624, elapse: 2.610 min, gpu memory usage=22194.000 MiB\n",
    "\"\"\"\n",
    "\n",
    "# pattern = regex.compile(r'(\\d+\\.\\d+)')\n",
    "pattern = regex.compile(r'scores: MRR:(\\d+\\.\\d+) hits@10:(\\d+\\.\\d+) map@10:(\\d+\\.\\d+) hits@50:(\\d+\\.\\d+) map@50:(\\d+\\.\\d+) hits@100:(\\d+\\.\\d+) map@100:(\\d+\\.\\d+)')\n",
    "m = pattern.findall(s)\n",
    "# print([float(e)*100 for e in m])\n",
    "for e in m:\n",
    "    print([float(e1)*100 for e1 in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.021878, 0.021638, 0.021893, 0.022251, 0.021882, 0.021877, 0.021966, 0.021929, 0.021998, 0.022015]\n",
      "wb densegat MRR 2.19 0.01\n",
      "[0.042377, 0.041456, 0.042304, 0.042873, 0.042143, 0.042289, 0.042523, 0.042128, 0.042201, 0.042523]\n",
      "wb densegat hits@10 4.23 0.03\n",
      "[0.016193, 0.015916, 0.01616, 0.016612, 0.016209, 0.01617, 0.016249, 0.016237, 0.016272, 0.016324]\n",
      "wb densegat map@10 1.62 0.02\n",
      "[0.117047, 0.117179, 0.118318, 0.117412, 0.117252, 0.118771, 0.119254, 0.117719, 0.118596, 0.118026]\n",
      "wb densegat hits@50 11.8 0.07\n",
      "[0.019394, 0.019151, 0.01943, 0.01979, 0.019414, 0.019425, 0.019511, 0.019461, 0.019539, 0.019566]\n",
      "wb densegat map@50 1.95 0.02\n",
      "[0.179034, 0.17937, 0.178683, 0.176652, 0.17785, 0.177646, 0.178815, 0.178026, 0.179019, 0.177543]\n",
      "wb densegat hits@100 17.83 0.08\n",
      "[0.020263, 0.020026, 0.020275, 0.02062, 0.020261, 0.02025, 0.020346, 0.020305, 0.020386, 0.020397]\n",
      "wb densegat map@100 2.03 0.01\n"
     ]
    }
   ],
   "source": [
    "# calculate error bars\n",
    "\n",
    "# 1. read from log files\n",
    "\n",
    "import regex\n",
    "import glob\n",
    "\n",
    "def split_filename(filename: str):\n",
    "    parts = filename.split('/')\n",
    "    if len(parts) < 2: return None\n",
    "    parts = parts[-1].split('_')\n",
    "    if len(parts) < 2: return None\n",
    "    idx = parts[1]\n",
    "    infos = parts[0].split('-')\n",
    "    if len(infos) < 3: return None\n",
    "    dataset = infos[0]\n",
    "    model = infos[1]\n",
    "    return dataset, model, idx\n",
    "\n",
    "def read_log_file(dirpath: str):\n",
    "    # 2024-06-30 07:13:14,658    - (Testing)    scores: MRR:0.224386 hits@10:0.222489 map@10:0.087642 hits@50:0.408720 map@50:0.096358 hits@100:0.490232 map@100:0.097533, elapse: 3.663 min, gpu memory usage=23832.000 MiB\n",
    "    pattern = regex.compile(r'scores: MRR:(\\d+\\.\\d+) hits@10:(\\d+\\.\\d+) map@10:(\\d+\\.\\d+) hits@50:(\\d+\\.\\d+) map@50:(\\d+\\.\\d+) hits@100:(\\d+\\.\\d+) map@100:(\\d+\\.\\d+)')\n",
    "    if dirpath[-1] != '/': dirpath += '/'\n",
    "\n",
    "    results = {}\n",
    "    for log_file in glob.glob(dirpath + \"*basic*.txt\"):\n",
    "        # print(log_file)\n",
    "        dataset, model, idx = split_filename(log_file)\n",
    "        if dataset not in results: results[dataset] = {}\n",
    "        if model not in results[dataset]: results[dataset][model] = {}\n",
    "        with open(log_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if \"scores\" in line:\n",
    "                    m = pattern.search(line)\n",
    "                    if m:\n",
    "                        results[dataset][model][idx] = m.groups()\n",
    "            # if dataset == \"wb\" and model == \"tan\":\n",
    "            #     print(dataset, model, idx, results[dataset][model][idx])\n",
    "    return results\n",
    "\n",
    "results = read_log_file(\"/root/pyHeter-GAT/src/\")\n",
    "\n",
    "# 2. calculate mean and std\n",
    "names = [\"MRR\", \"hits@10\", \"map@10\", \"hits@50\", \"map@50\", \"hits@100\", \"map@100\"]\n",
    "for dataset, models in results.items():\n",
    "    if dataset != 'wb': continue\n",
    "    for model, idxs in models.items():\n",
    "        if model != 'densegat': continue\n",
    "        scores = [[] for _ in range(len(names))]\n",
    "        for _, vals in idxs.items():\n",
    "            for idx, val in enumerate(vals): \n",
    "                scores[idx].append(float(val))\n",
    "        for idx, name in enumerate(names):\n",
    "            print(scores[idx])\n",
    "            mean = sum(scores[idx]) / len(idxs)\n",
    "            std = (sum([(score - mean) ** 2 for score in scores[idx]]) / len(idxs)) ** 0.5\n",
    "            print(dataset, model, name, round(mean*100, 2), round(std*100,2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1565068138590276, 0.15946014549664625, 0.15165694188479273, 0.15976805853100157, 0.1529991556635849, 0.15568861810622808, 0.15726053335098295, 0.1564570435429694, 0.16942183830637914, 0.15900262347244418]\n",
      "wb inf-vae MRR 15.78 0.46\n",
      "[0.013165574535775848, 0.013486941752489656, 0.01326584690232167, 0.013274490963653319, 0.013397486688225031, 0.013779555428633211, 0.014269735303154289, 0.013462739059643672, 0.013913708802677126, 0.01346270730585379]\n",
      "wb inf-vae hits@10 1.35 0.03\n",
      "[0.025989456771043716, 0.02753715266096991, 0.026657132618693836, 0.026759657518621062, 0.026166134547073866, 0.025453053865930997, 0.027800998239936384, 0.02776809928851594, 0.027595917259343287, 0.026271499246339786]\n",
      "wb inf-vae map@10 2.68 0.08\n",
      "[0.04923980054063875, 0.04967717722880837, 0.05007902963679854, 0.048818594353054676, 0.050922007892850805, 0.05239792801490654, 0.051616866113567125, 0.050651992615210556, 0.04974048000460114, 0.051591713930597236]\n",
      "wb inf-vae hits@50 5.05 0.11\n",
      "[0.013582190535606338, 0.01468747830036253, 0.014242519365449527, 0.013381596437627239, 0.014481270548821073, 0.01413517379247831, 0.014425046168871433, 0.01564581530008661, 0.013543178222655532, 0.014255948611799133]\n",
      "wb inf-vae map@50 1.42 0.06\n",
      "[0.08208659013651841, 0.08135214856383009, 0.08404121680256448, 0.08226366021512636, 0.08540722373058725, 0.08676746816124992, 0.0862839666648152, 0.08337507612718259, 0.08279735297015538, 0.08518923557989422]\n",
      "wb inf-vae hits@100 8.4 0.18\n",
      "[0.014547442182258554, 0.015740545944290366, 0.015422890474693786, 0.014540161650134519, 0.016080551731061123, 0.015487531541424926, 0.015954031003702716, 0.016780626855372665, 0.014605464559122207, 0.015478805094146897]\n",
      "wb inf-vae map@100 1.55 0.07\n"
     ]
    }
   ],
   "source": [
    "# /root/pyHeter-GAT/sota-dependencies/Inf-VAE/tw-inf_vae-basic_1.txt\n",
    "\n",
    "def read_json(dirpath: str):\n",
    "    import json\n",
    "    if dirpath[-1] != '/': dirpath += '/'\n",
    "    results = {}\n",
    "    for json_file in glob.glob(dirpath + \"*basic*.txt\"):\n",
    "        dataset = json_file.split('/')[-1][:2]\n",
    "        model = \"inf-vae\"\n",
    "        idx = json_file.split('_')[-1].split('.')[0]\n",
    "        if dataset not in results: results[dataset] = {}\n",
    "        if model not in results[dataset]: results[dataset][model] = {}\n",
    "        with open(json_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = lines[-7:]\n",
    "            j = json.loads(\"\".join([line[:-1] for line in lines]).replace(\"'\", '\"'))\n",
    "            results[dataset][model][idx] = [j['MRR'], j['Recall@10'], j['MAP@10'], j['Recall@50'], j['MAP@50'], j['Recall@100'], j['MAP@100']]\n",
    "    return results\n",
    "\n",
    "results2 = read_json(\"/root/pyHeter-GAT/sota-dependencies/Inf-VAE/\")\n",
    "\n",
    "# 2. calculate mean and std\n",
    "names = [\"MRR\", \"hits@10\", \"map@10\", \"hits@50\", \"map@50\", \"hits@100\", \"map@100\"]\n",
    "for dataset, models in results2.items():\n",
    "    if dataset != 'wb': continue\n",
    "    for model, idxs in models.items():\n",
    "        if model != 'inf-vae': continue\n",
    "        scores = [[] for _ in range(len(names))]\n",
    "        for _, vals in idxs.items():\n",
    "            for idx, val in enumerate(vals): \n",
    "                scores[idx].append(float(val))\n",
    "        for idx, name in enumerate(names):\n",
    "            print(scores[idx])\n",
    "            mean = sum(scores[idx]) / len(idxs)\n",
    "            std = (sum([(score - mean) ** 2 for score in scores[idx]]) / len(idxs)) ** 0.5\n",
    "            print(dataset, model, name, round(mean*100, 2), round(std*100,2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04328646, 0.04490156, 0.04290598, 0.04032197, 0.04344449, 0.04423909, 0.04343006, 0.04454645, 0.04387987, 0.04480376]\n",
      "tw hidan MRR 4.36 0.13\n",
      "[0.0885350317148, 0.0902300839472, 0.0880357371874, 0.0874544889942, 0.0879957695727, 0.0848574113939, 0.0870671686788, 0.0927711401221, 0.0855090317608, 0.0875854478433]\n",
      "tw hidan hits@10 8.8 0.21\n",
      "[0.131314696439, 0.136277876719, 0.136361005669, 0.133039159397, 0.135067994509, 0.129134734464, 0.134168219439, 0.133840113604, 0.130155842996, 0.130026951152]\n",
      "tw hidan map@10 13.29 0.25\n",
      "[0.155791499892, 0.161108687327, 0.159998911988, 0.158266892653, 0.158015420644, 0.154411890125, 0.160524689548, 0.157646878856, 0.157499195667, 0.155378318151]\n",
      "tw hidan hits@50 15.79 0.21\n",
      "[0.0565287712236, 0.0575794947885, 0.0562357785011, 0.0543411356068, 0.0562401148764, 0.0558649734891, 0.0552385091352, 0.0577958081016, 0.0562591731077, 0.0575048857881]\n",
      "tw hidan map@50 5.64 0.1\n",
      "[0.0583893248476, 0.0595739954451, 0.0584434661628, 0.0565776613029, 0.0584460840876, 0.0579079856295, 0.0573936253752, 0.0596394857585, 0.0582877980285, 0.0594479397962]\n",
      "tw hidan hits@100 5.84 0.09\n",
      "[0.0587353537962, 0.059935709127, 0.0587779962367, 0.0569295468268, 0.0587670122183, 0.0582692547534, 0.0577609523638, 0.0599764850786, 0.0586627270673, 0.0597958191297]\n",
      "tw hidan map@100 5.88 0.09\n"
     ]
    }
   ],
   "source": [
    "s = \"Test Results MRR: [0.04328646], ACC10: 0.0885350317148, ACC50: 0.131314696439, ACC100: 0.155791499892, MAP10: 0.0565287712236, MAP50: 0.0583893248476, MAP100: 0.0587353537962\"\n",
    "pattern = regex.compile(r'Test Results MRR: \\[(\\d+\\.\\d+)\\], ACC10: (\\d+\\.\\d+), ACC50: (\\d+\\.\\d+), ACC100: (\\d+\\.\\d+), MAP10: (\\d+\\.\\d+), MAP50: (\\d+\\.\\d+), MAP100: (\\d+\\.\\d+)')\n",
    "\n",
    "# /root/pyHeter-GAT/sota-dependencies/HiDAN_tf2/wb-hidan-basic_1.txt\n",
    "\n",
    "def read_json(dirpath: str):\n",
    "    import regex\n",
    "    import glob\n",
    "    if dirpath[-1] != '/': dirpath += '/'\n",
    "    pattern = regex.compile(r'Test Results MRR: \\[(\\d+\\.\\d+)\\], ACC10: (\\d+\\.\\d+), ACC50: (\\d+\\.\\d+), ACC100: (\\d+\\.\\d+), MAP10: (\\d+\\.\\d+), MAP50: (\\d+\\.\\d+), MAP100: (\\d+\\.\\d+)')\n",
    "    \n",
    "    results = {}\n",
    "    for json_file in glob.glob(dirpath + \"*basic*.txt\"):\n",
    "        dataset = json_file.split('/')[-1][:2]\n",
    "        model = \"hidan\"\n",
    "        idx = json_file.split('_')[-1].split('.')[0]\n",
    "        if dataset not in results: results[dataset] = {}\n",
    "        if model not in results[dataset]: results[dataset][model] = {}\n",
    "        with open(json_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = lines[-7:]\n",
    "            m = pattern.search(\"\".join([line[:-1] for line in lines]))\n",
    "            if m:\n",
    "                results[dataset][model][idx] = m.groups()\n",
    "    return results\n",
    "\n",
    "results2 = read_json(\"/root/pyHeter-GAT/sota-dependencies/HiDAN_tf2\")\n",
    "\n",
    "# 2. calculate mean and std\n",
    "names = [\"MRR\", \"hits@10\", \"map@10\", \"hits@50\", \"map@50\", \"hits@100\", \"map@100\"]\n",
    "for dataset, models in results2.items():\n",
    "    if dataset != 'tw': continue\n",
    "    for model, idxs in models.items():\n",
    "        if model != 'hidan': continue\n",
    "        scores = [[] for _ in range(len(names))]\n",
    "        for _, vals in idxs.items():\n",
    "            for idx, val in enumerate(vals): \n",
    "                scores[idx].append(float(val))\n",
    "        for idx, name in enumerate(names):\n",
    "            print(scores[idx])\n",
    "            mean = sum(scores[idx]) / len(idxs)\n",
    "            std = (sum([(score - mean) ** 2 for score in scores[idx]]) / len(idxs)) ** 0.5\n",
    "            print(dataset, model, name, round(mean*100, 2), round(std*100,2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.224386',\n",
       "  '0.222489',\n",
       "  '0.087642',\n",
       "  '0.408720',\n",
       "  '0.096358',\n",
       "  '0.490232',\n",
       "  '0.097533')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"2024-06-30 07:13:14,658    - (Testing)    scores: MRR:0.224386 hits@10:0.222489 map@10:0.087642 hits@50:0.408720 map@50:0.096358 hits@100:0.490232 map@100:0.097533, elapse: 3.663 min, gpu memory usage=23832.000 MiB\"\n",
    "pattern = regex.compile(r'scores: MRR:(\\d+\\.\\d+) hits@10:(\\d+\\.\\d+) map@10:(\\d+\\.\\d+) hits@50:(\\d+\\.\\d+) map@50:(\\d+\\.\\d+) hits@100:(\\d+\\.\\d+) map@100:(\\d+\\.\\d+)')\n",
    "\n",
    "m = pattern.findall(s)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filepath = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/\"\n",
    "filepath2 = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/\"\n",
    "\n",
    "def dump(filepath):\n",
    "    names = [\"u2idx.data\", \"train.data\", \"valid.data\", \"test.data\"]\n",
    "    for name in names:\n",
    "        with open(filepath + name, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        with open(filepath + \"{}2\".format(name), \"wb\") as f:\n",
    "            pickle.dump(data, f, protocol=2)\n",
    "\n",
    "# dump(filepath)\n",
    "dump(filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health | Military | Politics | Nature | Law | Society | Economy | Internet | Entertainment | Mass_media | Food_and_drink | Education | Government | Business | Religion | Technology | History | Sports | Culture | Humanities\n",
      "----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -----\n",
      "1050.835 | 573.438 | 672.918 | 515.951 | 754.073 | 532.977 | 483.418 | 292.440 | 318.216 | 253.522 | 65.052 | 125.804 | 261.168 | 40.454 | 45.260 | 11.927 | 9.413 | 9.489 | 9.709 | 184.593\n",
      "455.530 | 209.975 | 330.807 | 143.903 | 297.644 | 237.578 | 136.975 | 94.457 | 93.086 | 71.582 | 19.383 | 36.493 | 111.886 | 14.860 | 23.992 | 11.927 | 9.413 | 9.489 | 9.709 | -100.000\n",
      "1023.526 | 428.596 | 664.966 | 181.484 | 365.908 | 846.490 | 722.668 | 663.659 | 981.712 | 799.183 | 641.255 | 195.158 | -100.000 | 676.000 | 342.868 | 738.618 | -100.000 | 685.841 | -100.000 | 179.202\n",
      "1008.497 | 424.117 | 653.974 | 177.481 | 357.290 | 831.247 | 706.445 | 655.680 | 966.516 | 781.908 | 630.232 | 188.919 | -100.000 | 662.983 | 336.801 | 716.261 | -100.000 | 672.029 | -100.000 | -100.000\n",
      "1.202 | 0.703 | 0.807 | 0.643 | 0.892 | 0.661 | 0.609 | 0.410 | 0.437 | 0.369 | 0.172 | 0.236 | 0.377 | 0.147 | 0.152 | 0.117 | 0.114 | 0.114 | 0.115 | 0.297\n"
     ]
    }
   ],
   "source": [
    "# Re1 Calculate the number of edges in each graph\n",
    "import pickle\n",
    "\n",
    "filepath1 = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/topic_llm2/topic_diffusion_graph_full_windowsize7.data\"\n",
    "filepath2 = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/topic_llm2/topic_diffusion_graph_full_windowsize1.data\"\n",
    "\n",
    "filepath3 = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/topic_llm2/topic_diffusion_graph_full_windowsize7.data\"\n",
    "filepath4 = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/topic_llm2/topic_diffusion_graph_full_windowsize3.data\"\n",
    "\n",
    "data_mp = {}\n",
    "\n",
    "index = 0\n",
    "for filepath in [filepath1, filepath2, filepath3, filepath4]:\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        if key not in data_mp: data_mp[key] = []\n",
    "        data_mp[key].append(value.edge_index.shape[1])\n",
    "        # print(key, value.edge_index.shape[1])\n",
    "    for key, value in data_mp.items():\n",
    "        if len(value) != index + 1:\n",
    "            data_mp[key].append(0)\n",
    "        # print(key, len(data_mp[key]))\n",
    "    # print(key, len(value))\n",
    "    index += 1\n",
    "\n",
    "# for key, value in data_mp.items():\n",
    "#     print(key, value)\n",
    "\n",
    "num_edges = 110109\n",
    "names = [\"Politics\", \"Society\", \"Law\", \"Health\", \"Military\", \"Internet\", \"Religion\", \"Mass_media\", \"Entertainment\", \"Technology\", \"Economy\", \"Sports\", \"Government\", \"Business\", \"Culture\", \"Education\", \"Nature\", \"Humanities\", \"Food_and_drink\", \"History\"]\n",
    "print(\" | \".join([elem for elem in data_mp.keys() if elem in names]))\n",
    "print(\" | \".join([\"-----\" for elem in data_mp.keys() if elem in names]))\n",
    "for i in range(len(data_mp[\"Health\"])):\n",
    "    print(\" | \".join([\"{:.3f}\".format((data_mp[key][i] - num_edges) / num_edges * 100.0) for key in data_mp.keys() if key in names]))\n",
    "\n",
    "nodes = 10269\n",
    "# 保留三位小数\n",
    "print(\" | \".join([\"{:.3f}\".format(100 * data_mp[key][0] / nodes / (nodes-1)) for key in data_mp.keys() if key in names]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10269\n"
     ]
    }
   ],
   "source": [
    "# edges = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Weibo-Aminer/edges.data\"\n",
    "# edges = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/edges.data\"\n",
    "u2idx = \"/remote-home/share/dmb_nas/wangzejian/HeterGAT/Twitter-Huangxin/sub10000/u2idx.data\"\n",
    "\n",
    "with open(u2idx, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyHeter-GAT-_-uOEIOh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
